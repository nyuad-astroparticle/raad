{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data from NA\n",
    "\n",
    "A new approach to download the data from the NanoAvionics server that hopefully doesn't use their stupid classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from requests.auth import HTTPDigestAuth\n",
    "from requests_oauthlib import OAuth1\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import json\n",
    "from IPython.display import clear_output as clear\n",
    "\n",
    "import numpy as np\n",
    "import raadpy as rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a data download request using REST\n",
    "class RestOperations:\n",
    "    \"\"\"Send a data download request using the REST Protocol\n",
    "    \"\"\"\n",
    "    # Initialize with the link\n",
    "    def __init__(self, apiEndPoint, **kwargs):\n",
    "        \"\"\"Constructor\n",
    "\n",
    "        Args:\n",
    "            apiEndPoint (string): the url needed to make the request\n",
    "        \"\"\"\n",
    "        self.apiEndPoint = apiEndPoint\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def SendGetReq(self):\n",
    "        \"\"\"Send a download request to the URL\n",
    "\n",
    "        Returns:\n",
    "            json: A json file with all the downloaded data\n",
    "        \"\"\"\n",
    "        # Get the needed authorization information\n",
    "        auth = self.CallAuth(self.kwargs)\n",
    "\n",
    "        # Make the request\n",
    "        RespGetReq = requests.get(self.apiEndPoint, auth = auth, stream=True)\n",
    "\n",
    "        # Check for errors\n",
    "        if RespGetReq.status_code != 200:\n",
    "            RespGetReq.raise_for_status()\n",
    "            raise RuntimeError(f\"Request to {self.apiEndPoint} returned status code {RespGetReq.status_code}\")\n",
    "\n",
    "        # Convert the output to a json and return\n",
    "        return json.loads(RespGetReq.text)\n",
    "\n",
    "    def CallAuth(self, OptionalAttrs):\n",
    "        \"\"\"Handle authorization stuff\n",
    "\n",
    "        Args:\n",
    "            OptionalAttrs (_type_): The necessary arguments needed for the type of authorization\n",
    "\n",
    "        Returns:\n",
    "            auth: An authorization object\n",
    "        \"\"\"\n",
    "        authType = self.ValidateAuthAttrs(OptionalAttrs)\n",
    "        if not authType:\n",
    "            auth = None            \n",
    "        elif authType == 'token':\n",
    "            auth = HTTPBearerAuth(OptionalAttrs.get('token'))\n",
    "        elif authType == 'basic':\n",
    "            auth = HTTPBasicAuth(OptionalAttrs.get('username'), OptionalAttrs.get('password'))\n",
    "        elif authType  == 'digest':\n",
    "            auth = HTTPDigestAuth(OptionalAttrs.get('username'), OptionalAttrs.get('password'))\n",
    "        elif authType  == 'oa1':\n",
    "            auth = OAuth1(OptionalAttrs.get('AppKey'), OptionalAttrs.get('AppSecret'), OptionalAttrs.get('UserToken'), OptionalAttrs.get('UserSecret'))\n",
    "        return auth\n",
    "    \n",
    "    def ValidateAuthAttrs(self, OptionalAttrs):\n",
    "        \"\"\"Make sure the optinal attributes of this class exist\n",
    "        \"\"\"\n",
    "        if 'authType' not in OptionalAttrs:\n",
    "            authType = None\n",
    "        else:\n",
    "            if OptionalAttrs.get('authType') not in ['token', 'digest', 'basic', 'oa1']:\n",
    "                raise ValueError(\"Unknown authType received\", OptionalAttrs.get('authType'))\n",
    "            else:\n",
    "                if OptionalAttrs.get('authType') == 'token' and 'token' not in OptionalAttrs:\n",
    "                    raise ValueError(\"authType 'token' requires token\")\n",
    "                elif OptionalAttrs.get('authType') == 'basic' and not all(attr in OptionalAttrs for attr in ['username', 'password']):\n",
    "                    raise ValueError(\"authType 'basic' requires username, password\")\n",
    "                elif OptionalAttrs.get('authType') == 'digest' and not all(attr in OptionalAttrs for attr in ['username', 'password']):\n",
    "                    raise ValueError(\"authType 'digest' requires username, password\")\n",
    "                elif OptionalAttrs.get('authType') == 'oa1' and not all(attr in OptionalAttrs for attr in ['AppKey', 'AppSecret', 'UserToken' 'UserSecret']):\n",
    "                    raise ValueError(\"authType 'oa1' requires AppKey, AppSecret, UserToken, UserSecret\")\n",
    "                else:\n",
    "                    authType = OptionalAttrs.get('authType')\n",
    "        return authType\n",
    "\n",
    "class HTTPBearerAuth(requests.auth.AuthBase):\n",
    "    '''requests() does not support HTTP Bearer tokens authentication, create one'''\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "    def __eq__(self, other):\n",
    "        return self.token == getattr(other, 'token', None)\n",
    "    def __ne__(self, other):\n",
    "        return not self == other\n",
    "    def __call__(self, r):\n",
    "        r.headers['Authorization'] = 'Bearer ' + self.token\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tests\n",
    "\n",
    "# Generate some variables\n",
    "fileName=\"pc_se0_log\"\n",
    "fileName=\"pc_buff2\"\n",
    "host=\"https://light1.mcs.nanoavionics.com\"\n",
    "token=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4\"\n",
    "\n",
    "# Download a range of data based on some limit\n",
    "def download_range(url:str,token,limit:int=5000,VERBOSE:bool=False):\n",
    "    \"\"\"Downloads a range of data given a url and a token from the NA servers. \n",
    "    Automatically handles large file sizes.\n",
    "\n",
    "    Args:\n",
    "        url (str): the url from the NA server with the data to download from \n",
    "        token (str): The string value of the token for security authentication\n",
    "        limit (int, optional): Number of rows to download at one go. Large numbers make the server crash. Defaults to 5000.\n",
    "        VERBOSE (bool, optional): If true update statistics are printed while the fies is being downloaded. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        data (list): a list of the binary strings of the downloaded data\n",
    "    \"\"\"\n",
    "\n",
    "    # store the result\n",
    "    data        = []\n",
    "    last_data   = []\n",
    "    seq         = -1\n",
    "    cnt         = 0\n",
    "\n",
    "    # Keep downloading until there is nothing left\n",
    "    while True:\n",
    "        # Print how much data you have downloaded\n",
    "        clear(wait=True)\n",
    "        if VERBOSE: \n",
    "            print('Current File: ',url,'\\nEntries Downloaded:',len(data),'\\nLast Sequence Number:',seq,'\\nIterations:',cnt)\n",
    "            # find the number of bytes per entry\n",
    "            print('Bytes per entry: ',np.unique([len(d) for d in data]))\n",
    "            cnt+=1\n",
    "\n",
    "        # Do the REST stuff\n",
    "        rest = RestOperations(url+f'&limit={limit}&seq_nr=gte.{seq}', authType = 'token', token = token)\n",
    "       \n",
    "        # Download the data\n",
    "        last_data   = rest.SendGetReq()\n",
    "        data        += last_data\n",
    "\n",
    "        # If there are no more data exit\n",
    "        if len(last_data) < limit or seq == max([datum['seq_nr'] for datum in data]):\n",
    "            return data\n",
    "        \n",
    "        # Find the last sequence number\n",
    "        seq = max([datum['seq_nr'] for datum in data])\n",
    "\n",
    "\n",
    "# Create a rest request\n",
    "# rest = RestOperations(f'{host}/{fileName}_download?archived_ts', authType = 'token', token = token)\n",
    "\n",
    "# Download the data using the request\n",
    "# data = rest.SendGetReq()\n",
    "\n",
    "# data = download_range(f'{host}/{fileName}_download?seq_nr=lte.1000000',token,VERBOSE=True)\n",
    "\n",
    "# print(len(data),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working functions\n",
    "\n",
    "# Order the data according to entry number\n",
    "def sort(data,field='entry_nr'):\n",
    "    \"\"\"Sort the data based on a metadata field\n",
    "\n",
    "    Args:\n",
    "        data (array of dictionaries): The array of dictionaries from the downloaded data\n",
    "        field (str, optional): The metadata field to sort according to. Defaults to 'entry_nr'.\n",
    "\n",
    "    Returns:\n",
    "        sorted: Sorted list of lists\n",
    "    \"\"\"\n",
    "    if len(data) <= 1: return data\n",
    "    \n",
    "    # Get the indices\n",
    "    idx = np.argsort([d[field] for d in data])\n",
    "    \n",
    "    # Sorted array\n",
    "    sorted = [data[idx[i]] for i in range(len(data))]\n",
    "\n",
    "    return sorted\n",
    "\n",
    "# Download data based on various keys\n",
    "def download_file_ver(buffer:int = 1, file_ver=1):\n",
    "    \"\"\"Download a data from NA server with a common file version\n",
    "\n",
    "    Args:\n",
    "        buffer (int, optional): The buffer to download. Defaults to 1.\n",
    "        file_ver (int, optional): The file version number. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        data: list of dictionaries with the rows\n",
    "    \"\"\"\n",
    "    # Generate some variables\n",
    "    fileName=\"pc_buff\"+str(buffer)\n",
    "    host=\"https://light1.mcs.nanoavionics.com\"\n",
    "    token=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4\"\n",
    "    url = f'{host}/{fileName}_download?file_ver=eq.{file_ver}'\n",
    "\n",
    "    # Download the data using segmented download\n",
    "    data = download_range(url,token,VERBOSE=True)\n",
    "\n",
    "    # Sort the data\n",
    "    data = sort(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Download data based on various keys\n",
    "def download_log(start:str=None,end:str=None):\n",
    "    \"\"\"Download a log file from the NA version\n",
    "\n",
    "    Args:\n",
    "        file_ver (int, optional): The file version number. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        data: list of dictionaries with the rows\n",
    "    \"\"\"\n",
    "    # Generate some variables\n",
    "    fileName=\"pc_se0_log\"\n",
    "    host=\"https://light1.mcs.nanoavionics.com\"\n",
    "    token=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4\"\n",
    "    url = f'{host}/{fileName}_download?'\n",
    "    if start is not None: \n",
    "        url += f'archived_ts=gte.{start}'\n",
    "        if end is not None: url += f'&archived_ts=lt.{end}'\n",
    "    elif end is not None: url += f'archived_ts=lt.{end}'\n",
    "\n",
    "    # Download the data using segmented download\n",
    "    data = download_range(url,token,VERBOSE=True)\n",
    "\n",
    "    # Sort the data\n",
    "    data = sort(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Download data based on time range\n",
    "def download_time_delta(buffer:int = 1, start:str=None, end:str=None):\n",
    "    \"\"\"Download NA data on a time interval \n",
    "\n",
    "    Args:\n",
    "        buffer (int, optional): The buffer number. Defaults to 1.\n",
    "        start (str, optional): String with iso date to start. Defaults to '2022-06-01T00:00:00'.\n",
    "        end (str, optional): String with iso date to end. Defaults to '2022-06-07T00:00:00'.\n",
    "\n",
    "    Returns:\n",
    "        data: list of dictionaries with the rows\n",
    "    \"\"\"\n",
    "    # Generate some variables\n",
    "    fileName=\"pc_buff\"+str(buffer)\n",
    "    host=\"https://light1.mcs.nanoavionics.com\"\n",
    "    token=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4\"\n",
    "    url = f'{host}/{fileName}_download?'\n",
    "    if start is not None: \n",
    "        url += f'archived_ts=gte.{start}'\n",
    "        if end is not None: url += f'&archived_ts=lt.{end}'\n",
    "    elif end is not None: url += f'archived_ts=lt.{end}'\n",
    "\n",
    "    # Download the data using segmented download\n",
    "    data = download_range(url,token,VERBOSE=True)\n",
    "\n",
    "    # Sort the data\n",
    "    data = sort(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Save this data to a file to avoid having them in memory\n",
    "def save_raw_data(data,filepath:str='./',buffer:int=1):\n",
    "    \"\"\"Save the raw data to a file in the computer\n",
    "\n",
    "    Args:\n",
    "        data (_type_): The raw data downloaded from NA server\n",
    "        filepath (str, optional): The path that you want to save the file to. Defaults to './'.\n",
    "        buffer (int, optional): The buffer number. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        string: The filename of the file.\n",
    "    \"\"\"\n",
    "    # Create the filename\n",
    "    timestamp   = '2022-NA-NAT' if len(data) == 0 else data[0]['archived_ts']\n",
    "    date        = timestamp[0:timestamp.index('T')]\n",
    "    filename    = filepath + f'light1-{date}-buff{buffer}.dat'\n",
    "\n",
    "    # Load the file to write the output\n",
    "    file = open(filename,'wb')\n",
    "\n",
    "    # Append the data\n",
    "    for row in data:\n",
    "        # Convert the hexadecimal entry to bytes\n",
    "        entry = bytes.fromhex(row['entry_data'][2:])\n",
    "        file.write(entry)\n",
    "    \n",
    "    # Close the file\n",
    "    file.close()\n",
    "\n",
    "    # Return the filename if you need it\n",
    "    return filename\n",
    "\n",
    "# Convert from binary\n",
    "def log_to_ascii(data,fileName:str=None):\n",
    "    \"\"\"Decode binary log file to ascii\n",
    "\n",
    "    Args:\n",
    "        data (dictionary): The dictionary obtained from the downloaded NA code\n",
    "        fileName (str, optional): Filename to export the logfile to. If None then the file is not exported. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: The decoded logfile as a string\n",
    "    \"\"\"\n",
    "    # Store the full decoded text here\n",
    "    full_text = ''\n",
    "\n",
    "    # For every line in the logfile\n",
    "    for entry in data:\n",
    "        line =  bytes.fromhex(entry['entry_data'][2:]).decode(\"ASCII\")\n",
    "        full_text += line\n",
    "\n",
    "    # If you need to store do so\n",
    "    if fileName is not None: \n",
    "        file = open(fileName,'w')\n",
    "        file.write(full_text)\n",
    "        file.close()\n",
    "\n",
    "    # Return the full text\n",
    "    return full_text\n",
    "\n",
    "# Parse a logfile and obtain metadata\n",
    "def log_expand(filename:str=None,text:str=None):\n",
    "    \"\"\"Gets a logfile and decodes it to a list of commands. \n",
    "    If a text value is given then it decodes the text, if not, it then decodes the value from the filename\n",
    "\n",
    "    Args:\n",
    "        text (str, optional): The text of the logfile. Defaults to None.\n",
    "        filename (str, optional): The filename of the file where the logfile is. Defaults to None.\n",
    "\n",
    "    Raises:\n",
    "        BaseException: If both parameters are left as None, then nothing happens. \n",
    "\n",
    "    Returns:\n",
    "        decoded_logfile (list): List of lists. Each entry is a tuple with a command and a list for the outputs. \n",
    "    \"\"\"\n",
    "\n",
    "    # Do some argument processing:\n",
    "    if filename is not None:\n",
    "        # Load the logfile\n",
    "        logfile = open(filename)\n",
    "\n",
    "        # Load the lines\n",
    "        loglines = logfile.readlines()\n",
    "\n",
    "        # Close the file\n",
    "        logfile.close()\n",
    "\n",
    "    elif text is not None:\n",
    "        loglines = text.split('\\n')\n",
    "\n",
    "    else: raise BaseException(\"Please enter input\")\n",
    "\n",
    "    # Add an SE0> line at the end if it doesn't exist\n",
    "    if \"SE0>\" not in loglines[-1]: loglines.append(\"SE0>\")\n",
    "\n",
    "    # Decode the file\n",
    "    # Find the indices of hte command lines\n",
    "    commands_idx = [i for i,line in enumerate(loglines) if 'SE0>' in line]\n",
    "    \n",
    "    # Collect the outputs of the commands\n",
    "    decoded_log = [[loglines[commands_idx[i]],loglines[commands_idx[i]+1:commands_idx[i+1]]] for i in range(len(commands_idx)-1)]\n",
    "\n",
    "    # Return\n",
    "    return decoded_log\n",
    "    \n",
    "\n",
    "# Parse custom command from satellite\n",
    "def parse_custom_scenario(cmd:str):\n",
    "    \"\"\"Parses a custom scenario command message string to a dictionary of decoded hex values\n",
    "\n",
    "    Args:\n",
    "        cmd (str): Teh command message\n",
    "\n",
    "    Returns:\n",
    "        dict: The dictionary with outputs of all the relevant parameters set for the particular payload\n",
    "    \"\"\"\n",
    "    # Store the data in a dictionary\n",
    "    data = {}\n",
    "\n",
    "    # Decode the information from the string\n",
    "    data['hv']          = int(cmd[0:4],base=16)\n",
    "    data['veto_hv']     = int(cmd[4:8],base=16)\n",
    "    data['ch0_thresh']  = int(cmd[10:12]+cmd[8:10],base=16)\n",
    "    data['ch1_thresh']  = int(cmd[14:16]+cmd[12:14],base=16)\n",
    "    data['ch2_thresh']  = int(cmd[18:20]+cmd[16:18],base=16)\n",
    "    data['ch3_thresh']  = int(cmd[22:24]+cmd[20:22],base=16)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Obtain the metadata from a parsed logfile\n",
    "def log_metadata(decoded_log:list):\n",
    "\n",
    "    # metadata array initialization\n",
    "    metadata = {\n",
    "        'start_time':       None,\n",
    "        'end_time':         None,\n",
    "        'hv_SiPM':          -1,\n",
    "        'hv_PMT':           -1,\n",
    "        'hv_veto_SiPM':     -1,\n",
    "        'hv_veto_PMT':      -1,\n",
    "        'thresholds_SiPM':{\n",
    "            'channel_0':    0,\n",
    "            'channel_1':    0,\n",
    "            'channel_2':    0,\n",
    "            'channel_3':    0,\n",
    "        },\n",
    "        'thresholds_PMT':{\n",
    "            'channel_0':    0,\n",
    "            'channel_1':    0,\n",
    "            'channel_2':    0,\n",
    "            'channel_3':    0,\n",
    "        },\n",
    "        'custom_scenario_PMT': -1,\n",
    "        'custom_scenario_SiPM': -1\n",
    "    }\n",
    "\n",
    "    # Get the command list\n",
    "    commands = [row[0] for row in decoded_log]\n",
    "\n",
    "    # Find the start and end of the data acquisition\n",
    "    # Index of start and end timestamps:\n",
    "    start = [i for i in range(len(commands)) if \"rtc read\" in commands[i]]\n",
    "    if len(start) != 0: metadata['start_time']  = decoded_log[start[0] ][1][0][-21:-2]\n",
    "    if len(start) >= 2: metadata['end_time']    = decoded_log[start[-1]][1][0][-21:-2]\n",
    "\n",
    "    # Find the custom scenario commands for SiPM and PMT\n",
    "    for num,payload in zip([12,13],['SiPM','PMT']):\n",
    "        # Get all the commands with the custom scenario\n",
    "        custom_commands = np.unique([commands[i] for i in range(len(commands)) if f\"csp txrx {num} 9 3000\" in commands[i]])\n",
    "        \n",
    "        # If there are any, decode them and replace\n",
    "        if len(custom_commands) != 0: \n",
    "            message = custom_commands[0].split(' ')[-1][:-1]\n",
    "            data    = parse_custom_scenario(message)\n",
    "\n",
    "            # Update the decoded data to the metadata\n",
    "            metadata['hv_'+payload]                         = data['hv']\n",
    "            metadata['hv_veto_'+payload]                    = data['veto_hv']\n",
    "            metadata['thresholds_'+payload]['channel_0']    = data['ch0_thresh']\n",
    "            metadata['thresholds_'+payload]['channel_1']    = data['ch1_thresh']\n",
    "            metadata['thresholds_'+payload]['channel_2']    = data['ch2_thresh']\n",
    "            metadata['thresholds_'+payload]['channel_3']    = data['ch3_thresh']\n",
    "            metadata['custom_scenario_'+payload]            = message\n",
    "        \n",
    "\n",
    "    # Return the metadata\n",
    "    return metadata\n",
    "            \n",
    "\n",
    "# Download script packet\n",
    "def download_data_packet(start:str=None,end:str=None,filepath:str='./'):\n",
    "    \"\"\"Download a packet of data from light-1 NA Server. This is the main library used.\n",
    "\n",
    "    Args:\n",
    "        start (str, optional): The start timestamp iso. Defaults to None.\n",
    "        end (str, optional): The end timestmap in iso. Defaults to None.\n",
    "        filepath (str, optional): The filepath to save everyhing. Defaults to './'.\n",
    "\n",
    "    Returns:\n",
    "        str: list of filenames to return\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a directory to store all this data\n",
    "    if start is not None: filepath += 'light1-'+start[:start.index('T')]+'/'\n",
    "    else: filepath += 'light1-data/'\n",
    "    os.mkdir(filepath)\n",
    "\n",
    "    # List that holds all the filenames\n",
    "    filenames = []\n",
    "\n",
    "    # First go ahead and download all the buffers\n",
    "    for i in tqdm(range(1,10),desc='Downloading Buffer'):\n",
    "        # Download the data of the buffer\n",
    "        data    = download_time_delta(buffer=i,start=start,end=end)\n",
    "\n",
    "        # Save the data of the buffer\n",
    "        fname   = save_raw_data(data,filepath=filepath,buffer=i)\n",
    "        filenames.append(fname)\n",
    "\n",
    "    # Download the script log\n",
    "    log         = download_log(start=start,end=end)\n",
    "    if start is not None: log = log_to_ascii(log,fileName=filepath+'light1-'+start[:start.index('T')]+'-se-log.txt')\n",
    "    else: log = log_to_ascii(log,fileName=filepath+'light1-se-log.txt')\n",
    "    decoded_log = log_expand(text=log)\n",
    "\n",
    "    # Extract the metadata from the logfile\n",
    "    metadata = log_metadata(decoded_log=decoded_log)\n",
    "\n",
    "    # Save the datafile as a json on the same directory\n",
    "    with open(filepath + \"metadata.json\",\"w\") as meta_file: json.dump(metadata,meta_file,indent=4)\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries Downloaded: 0 \n",
      "Last Sequence Number: -1 \n",
      "Iterations: 0\n",
      "Bytes per entry:  []\n"
     ]
    }
   ],
   "source": [
    "filenames = download_data_packet(start='2022-08-28T00:00:00', end='2022-08-29T23:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries Downloaded: 5000 \n",
      "Last Sequence Number: 40791 \n",
      "Iterations: 1\n",
      "Bytes per entry:  [5]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/panos/Documents/NYU/6.Extracurricular/23.Cubesat/raad/Data_Analysis/Data_Download/Download_NA_New.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/panos/Documents/NYU/6.Extracurricular/23.Cubesat/raad/Data_Analysis/Data_Download/Download_NA_New.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m filenames \u001b[39m=\u001b[39m download_data_packet()\n",
      "\u001b[1;32m/Users/panos/Documents/NYU/6.Extracurricular/23.Cubesat/raad/Data_Analysis/Data_Download/Download_NA_New.ipynb Cell 7\u001b[0m in \u001b[0;36mdownload_data_packet\u001b[0;34m(start, end, filepath)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/panos/Documents/NYU/6.Extracurricular/23.Cubesat/raad/Data_Analysis/Data_Download/Download_NA_New.ipynb#W6sZmlsZQ%3D%3D?line=322'>323</a>\u001b[0m \u001b[39m# Download the script log\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/panos/Documents/NYU/6.Extracurricular/23.Cubesat/raad/Data_Analysis/Data_Download/Download_NA_New.ipynb#W6sZmlsZQ%3D%3D?line=323'>324</a>\u001b[0m log         \u001b[39m=\u001b[39m download_log(start\u001b[39m=\u001b[39mstart,end\u001b[39m=\u001b[39mend)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/panos/Documents/NYU/6.Extracurricular/23.Cubesat/raad/Data_Analysis/Data_Download/Download_NA_New.ipynb#W6sZmlsZQ%3D%3D?line=324'>325</a>\u001b[0m log         \u001b[39m=\u001b[39m log_to_ascii(log,fileName\u001b[39m=\u001b[39mfilepath\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlight1-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mstart[:start\u001b[39m.\u001b[39;49mindex(\u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m)]\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m-se-log.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/panos/Documents/NYU/6.Extracurricular/23.Cubesat/raad/Data_Analysis/Data_Download/Download_NA_New.ipynb#W6sZmlsZQ%3D%3D?line=325'>326</a>\u001b[0m decoded_log \u001b[39m=\u001b[39m log_expand(text\u001b[39m=\u001b[39mlog)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/panos/Documents/NYU/6.Extracurricular/23.Cubesat/raad/Data_Analysis/Data_Download/Download_NA_New.ipynb#W6sZmlsZQ%3D%3D?line=327'>328</a>\u001b[0m \u001b[39m# Extract the metadata from the logfile\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "filenames = download_data_packet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('RAAD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fd2e6389a0fd7c635319bf7383768acfaf026bf5f56a6bed54341f1b15812d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
